{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "037b53ac",
   "metadata": {},
   "source": [
    "# DATASCI 290 — Mini SNOMED Knowledge Graph (Public Snowstorm → Neo4j AuraDB)\n",
    "\n",
    "This notebook is a scaffold to help you go from **SNOMED CT concepts** to a small **property-graph KG** in **Neo4j AuraDB**.\n",
    "\n",
    "You will:\n",
    "- fetch concepts + relationships from a public Snowstorm training API\n",
    "- build a bounded mini-KG (small on purpose)\n",
    "- load it into Neo4j AuraDB\n",
    "- run verification queries\n",
    "\n",
    "You do not install Snowstorm. You only call its public API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8449ddf9",
   "metadata": {},
   "source": [
    "## 0) Install dependencies (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d87771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed:\n",
    "# !pip install requests pandas neo4j\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from typing import Dict, List, Tuple, Optional, Set\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec407cc6",
   "metadata": {},
   "source": [
    "## 1) Configuration\n",
    "\n",
    "A) Public Snowstorm endpoints (training).  \n",
    "B) Neo4j AuraDB credentials (student-specific).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d82b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowstorm (PUBLIC TRAINING)\n",
    "SNOWSTORM_FHIR_BASE = \"https://snowstorm-training.snomedtools.org/fhir\"\n",
    "SNOWSTORM_REST_BASE = \"https://snowstorm-training.snomedtools.org/snowstorm/snomed-ct\"\n",
    "BRANCH = \"MAIN\"\n",
    "SNOMED_SYSTEM = \"http://snomed.info/sct\"\n",
    "SNOWSTORM_BEARER_TOKEN = \"\"  # leave blank\n",
    "\n",
    "# Be polite to shared servers\n",
    "MIN_SLEEP_SEC = 0.05\n",
    "MAX_RETRIES_429 = 8\n",
    "\n",
    "# Neo4j AuraDB (fill these)\n",
    "NEO4J_URI = os.environ.get(\"NEO4J_URI\", \"neo4j+s://YOUR_AURA_HOST.databases.neo4j.io\")\n",
    "NEO4J_USER = os.environ.get(\"NEO4J_USER\", \"neo4j\")\n",
    "NEO4J_PASSWORD = os.environ.get(\"NEO4J_PASSWORD\", \"YOUR_PASSWORD\")\n",
    "\n",
    "# Scope controls (keep KG small)\n",
    "MAX_TOTAL_CONCEPTS = 800\n",
    "MAX_ATTR_NEIGHBORS = 3\n",
    "MAX_HOPS_ATTR = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf792807",
   "metadata": {},
   "source": [
    "## 2) Robust HTTP helpers (handles 429 rate limiting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84805dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _headers_json() -> Dict[str, str]:\n",
    "    h = {\"Accept\": \"application/json\", \"User-Agent\": \"DATASCI290-Snowstorm-Client/1.0\"}\n",
    "    if SNOWSTORM_BEARER_TOKEN:\n",
    "        h[\"Authorization\"] = f\"Bearer {SNOWSTORM_BEARER_TOKEN}\"\n",
    "    return h\n",
    "\n",
    "def _headers_fhir() -> Dict[str, str]:\n",
    "    h = {\"Accept\": \"application/fhir+json\", \"User-Agent\": \"DATASCI290-Snowstorm-Client/1.0\"}\n",
    "    if SNOWSTORM_BEARER_TOKEN:\n",
    "        h[\"Authorization\"] = f\"Bearer {SNOWSTORM_BEARER_TOKEN}\"\n",
    "    return h\n",
    "\n",
    "def _get(url: str, headers: Dict[str, str], params: Optional[Dict] = None, max_retries: int = MAX_RETRIES_429) -> Dict:\n",
    "    params = params or {}\n",
    "    backoff = 1.0\n",
    "    for attempt in range(max_retries):\n",
    "        r = requests.get(url, headers=headers, params=params, timeout=60)\n",
    "        if r.status_code == 429:\n",
    "            retry_after = r.headers.get(\"Retry-After\")\n",
    "            sleep_s = backoff\n",
    "            if retry_after is not None:\n",
    "                try:\n",
    "                    sleep_s = float(retry_after)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            sleep_s += random.uniform(0, 0.25)\n",
    "            print(f\"[429] Rate limited. Sleeping {sleep_s:.2f}s (attempt {attempt+1}/{max_retries})\")\n",
    "            time.sleep(sleep_s)\n",
    "            backoff = min(backoff * 2, 30.0)\n",
    "            continue\n",
    "        r.raise_for_status()\n",
    "        time.sleep(MIN_SLEEP_SEC)\n",
    "        return r.json()\n",
    "    raise RuntimeError(\"Exceeded retry budget due to repeated 429 responses.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caff8287",
   "metadata": {},
   "source": [
    "## 3) Snowstorm FHIR: $lookup (SCTID → preferred label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb5e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fhir_get(path: str, params: Optional[Dict] = None) -> Dict:\n",
    "    url = SNOWSTORM_FHIR_BASE.rstrip(\"/\") + \"/\" + path.lstrip(\"/\")\n",
    "    return _get(url, headers=_headers_fhir(), params=params)\n",
    "\n",
    "def snomed_lookup_display(sctid: str) -> str:\n",
    "    out = fhir_get(\"CodeSystem/$lookup\", params={\"system\": SNOMED_SYSTEM, \"code\": sctid})\n",
    "    if \"display\" in out:\n",
    "        return out[\"display\"]\n",
    "    for p in out.get(\"parameter\", []):\n",
    "        if p.get(\"name\") == \"display\":\n",
    "            return p.get(\"valueString\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "cap = fhir_get(\"metadata\")\n",
    "print(\"FHIR server OK. Software:\", cap.get(\"software\", {}).get(\"name\"), cap.get(\"software\", {}).get(\"version\"))\n",
    "print(\"Example lookup 29857009:\", snomed_lookup_display(\"29857009\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b16c999",
   "metadata": {},
   "source": [
    "## 4) Snowstorm REST: search concepts by text (find seed SCTIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c35c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rest_get(path: str, params: Optional[Dict] = None) -> Dict:\n",
    "    url = SNOWSTORM_REST_BASE.rstrip(\"/\") + \"/\" + path.lstrip(\"/\")\n",
    "    return _get(url, headers=_headers_json(), params=params)\n",
    "\n",
    "def search_concepts(term: str, limit: int = 10, active: bool = True) -> List[Dict]:\n",
    "    out = rest_get(f\"{BRANCH}/concepts\", params={\n",
    "        \"term\": term, \"limit\": limit, \"offset\": 0, \"activeFilter\": str(active).lower()\n",
    "    })\n",
    "    return out.get(\"items\", [])\n",
    "\n",
    "hits = search_concepts(\"chest pain\", limit=5)\n",
    "for h in hits:\n",
    "    cid = h.get(\"conceptId\")\n",
    "    pt = (h.get(\"pt\") or {}).get(\"term\")\n",
    "    fsn = (h.get(\"fsn\") or {}).get(\"term\")\n",
    "    print(cid, \"|\", pt, \"|\", fsn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548959cb",
   "metadata": {},
   "source": [
    "## 5) Choose your scope + seeds (10–20 SCTIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a9decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_CONCEPTS = [\n",
    "    # TODO: paste 10–20 SCTIDs here\n",
    "    # Example:\n",
    "    # \"29857009\",  # Chest pain\n",
    "]\n",
    "\n",
    "assert len(SEED_CONCEPTS) > 0, \"Fill SEED_CONCEPTS with 10–20 SCTIDs.\"\n",
    "print(\"Seed count:\", len(SEED_CONCEPTS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6570292",
   "metadata": {},
   "source": [
    "## 6) Fetch concept JSON (parents + relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde0294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concept_browser(concept_id: str) -> Dict:\n",
    "    return rest_get(f\"browser/{BRANCH}/concepts/{concept_id}\")\n",
    "\n",
    "def parse_parents(concept_json: Dict) -> List[str]:\n",
    "    parents = []\n",
    "    for p in concept_json.get(\"parents\", []):\n",
    "        if isinstance(p, dict) and \"conceptId\" in p:\n",
    "            parents.append(str(p[\"conceptId\"]))\n",
    "        elif isinstance(p, str):\n",
    "            parents.append(p)\n",
    "    return parents\n",
    "\n",
    "def parse_attribute_relationships(concept_json: Dict) -> List[Tuple[str, str, str]]:\n",
    "    rels = []\n",
    "    for r in concept_json.get(\"relationships\", []):\n",
    "        if not isinstance(r, dict):\n",
    "            continue\n",
    "        if r.get(\"active\") is False:\n",
    "            continue\n",
    "        type_obj = r.get(\"type\") or {}\n",
    "        type_id = str(type_obj.get(\"conceptId\", \"\"))\n",
    "        if type_id == \"116680003\":  # IS_A\n",
    "            continue\n",
    "        type_term = \"\"\n",
    "        pt = type_obj.get(\"pt\")\n",
    "        if isinstance(pt, dict):\n",
    "            type_term = pt.get(\"term\", \"\")\n",
    "        target = r.get(\"target\") or {}\n",
    "        dest_id = str(target.get(\"conceptId\", \"\"))\n",
    "        if type_id and dest_id:\n",
    "            rels.append((type_id, type_term, dest_id))\n",
    "    return rels\n",
    "\n",
    "test_id = SEED_CONCEPTS[0]\n",
    "cj = get_concept_browser(test_id)\n",
    "print(\"PT:\", (cj.get(\"pt\") or {}).get(\"term\"))\n",
    "print(\"Parents:\", parse_parents(cj)[:5])\n",
    "print(\"Attr rels sample:\", parse_attribute_relationships(cj)[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8372f9db",
   "metadata": {},
   "source": [
    "## 7) Build the bounded mini-KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52503336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mini_kg(seeds: List[str], max_total: int, max_attr_neighbors: int, max_hops_attr: int):\n",
    "    concepts: Set[str] = set()\n",
    "    isa_edges: Set[Tuple[str, str]] = set()\n",
    "    rel_edges: Set[Tuple[str, str, str, str]] = set()\n",
    "    cache: Dict[str, Dict] = {}\n",
    "\n",
    "    def get_cached(cid: str) -> Dict:\n",
    "        if cid not in cache:\n",
    "            cache[cid] = get_concept_browser(cid)\n",
    "        return cache[cid]\n",
    "\n",
    "    frontier: List[Tuple[str, int]] = [(s, 0) for s in seeds]\n",
    "    seen: Set[str] = set(seeds)\n",
    "\n",
    "    while frontier and len(concepts) < max_total:\n",
    "        cid, depth = frontier.pop(0)\n",
    "        concepts.add(cid)\n",
    "        cj = get_cached(cid)\n",
    "\n",
    "        # IS_A parents\n",
    "        for p in parse_parents(cj):\n",
    "            isa_edges.add((cid, p))\n",
    "            if p not in concepts and len(concepts) < max_total:\n",
    "                concepts.add(p)\n",
    "            if p not in seen and len(concepts) < max_total:\n",
    "                frontier.append((p, depth))\n",
    "                seen.add(p)\n",
    "\n",
    "        # Attribute edges (bounded)\n",
    "        rels = parse_attribute_relationships(cj)[:max_attr_neighbors]\n",
    "        for (type_id, type_term, dst) in rels:\n",
    "            rel_edges.add((cid, type_id, type_term, dst))\n",
    "            if dst not in concepts and len(concepts) < max_total:\n",
    "                concepts.add(dst)\n",
    "            if depth < max_hops_attr and dst not in seen and len(concepts) < max_total:\n",
    "                frontier.append((dst, depth + 1))\n",
    "                seen.add(dst)\n",
    "\n",
    "    # Ancestor closure (bounded)\n",
    "    changed = True\n",
    "    while changed and len(concepts) < max_total:\n",
    "        changed = False\n",
    "        for cid in list(concepts):\n",
    "            try:\n",
    "                cj = get_cached(cid)\n",
    "            except Exception:\n",
    "                continue\n",
    "            for p in parse_parents(cj):\n",
    "                if (cid, p) not in isa_edges:\n",
    "                    isa_edges.add((cid, p))\n",
    "                    changed = True\n",
    "                if p not in concepts and len(concepts) < max_total:\n",
    "                    concepts.add(p)\n",
    "                    changed = True\n",
    "\n",
    "    return concepts, isa_edges, rel_edges\n",
    "\n",
    "concepts, isa_edges, rel_edges = build_mini_kg(\n",
    "    seeds=SEED_CONCEPTS,\n",
    "    max_total=MAX_TOTAL_CONCEPTS,\n",
    "    max_attr_neighbors=MAX_ATTR_NEIGHBORS,\n",
    "    max_hops_attr=MAX_HOPS_ATTR,\n",
    ")\n",
    "\n",
    "print(\"Concepts:\", len(concepts))\n",
    "print(\"IS_A edges:\", len(isa_edges))\n",
    "print(\"REL edges:\", len(rel_edges))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b58f0",
   "metadata": {},
   "source": [
    "## 8) Create node/edge tables (inspect before loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937227eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cache: Dict[str, str] = {}\n",
    "\n",
    "def display_for(cid: str) -> str:\n",
    "    if cid not in display_cache:\n",
    "        display_cache[cid] = snomed_lookup_display(cid)\n",
    "    return display_cache[cid]\n",
    "\n",
    "df_concepts = pd.DataFrame([{\"sctid\": c, \"pt\": display_for(c)} for c in sorted(concepts)])\n",
    "df_isa = pd.DataFrame(sorted(list(isa_edges)), columns=[\"child\", \"parent\"])\n",
    "df_rel = pd.DataFrame(sorted(list(rel_edges)), columns=[\"src\", \"typeId\", \"typeTerm\", \"dst\"])\n",
    "\n",
    "df_concepts.head(), df_isa.head(), df_rel.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002804e",
   "metadata": {},
   "source": [
    "## 9) Load into Neo4j AuraDB (MERGE upserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d09b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "def run_cypher(q: str, params: Optional[Dict] = None):\n",
    "    with driver.session() as session:\n",
    "        return session.run(q, params or {}).data()\n",
    "\n",
    "# Constraint\n",
    "run_cypher(\"CREATE CONSTRAINT concept_sctid IF NOT EXISTS FOR (c:Concept) REQUIRE c.sctid IS UNIQUE\")\n",
    "\n",
    "def upsert_concepts(rows: List[Dict], batch_size: int = 500):\n",
    "    q = \"\"\"\n",
    "    UNWIND $rows AS row\n",
    "    MERGE (c:Concept {sctid: row.sctid})\n",
    "    SET c.pt = row.pt\n",
    "    \"\"\"\n",
    "    for i in range(0, len(rows), batch_size):\n",
    "        run_cypher(q, {\"rows\": rows[i:i+batch_size]})\n",
    "\n",
    "def upsert_isa(rows: List[Dict], batch_size: int = 1000):\n",
    "    q = \"\"\"\n",
    "    UNWIND $rows AS row\n",
    "    MATCH (child:Concept {sctid: row.child})\n",
    "    MATCH (parent:Concept {sctid: row.parent})\n",
    "    MERGE (child)-[:IS_A]->(parent)\n",
    "    \"\"\"\n",
    "    for i in range(0, len(rows), batch_size):\n",
    "        run_cypher(q, {\"rows\": rows[i:i+batch_size]})\n",
    "\n",
    "def upsert_rel(rows: List[Dict], batch_size: int = 1000):\n",
    "    q = \"\"\"\n",
    "    UNWIND $rows AS row\n",
    "    MATCH (src:Concept {sctid: row.src})\n",
    "    MATCH (dst:Concept {sctid: row.dst})\n",
    "    MERGE (src)-[r:REL {typeId: row.typeId}]->(dst)\n",
    "    SET r.typeTerm = row.typeTerm\n",
    "    \"\"\"\n",
    "    for i in range(0, len(rows), batch_size):\n",
    "        run_cypher(q, {\"rows\": rows[i:i+batch_size]})\n",
    "\n",
    "upsert_concepts(df_concepts.to_dict(\"records\"))\n",
    "upsert_isa(df_isa.to_dict(\"records\"))\n",
    "upsert_rel(df_rel.to_dict(\"records\"))\n",
    "\n",
    "print(\"Loaded into AuraDB.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bba7b1f",
   "metadata": {},
   "source": [
    "## 10) Verification queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cypher(\"\"\"\n",
    "MATCH (c:Concept) WITH count(c) AS concept_nodes\n",
    "MATCH ()-[r:IS_A]->() WITH concept_nodes, count(r) AS isa_edges\n",
    "MATCH ()-[r:REL]->() RETURN concept_nodes, isa_edges, count(r) AS rel_edges\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6523e9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = SEED_CONCEPTS[0]\n",
    "run_cypher(\"\"\"\n",
    "MATCH p = (c:Concept {sctid: $seed})-[:IS_A*1..3]->(a:Concept)\n",
    "RETURN c.pt AS seed_term, [n IN nodes(p)[1..] | n.pt] AS ancestors\n",
    "LIMIT 10\n",
    "\"\"\", {\"seed\": seed})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b9e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = SEED_CONCEPTS[0]\n",
    "run_cypher(\"\"\"\n",
    "MATCH (c:Concept {sctid: $seed})-[r:REL]->(d:Concept)\n",
    "RETURN c.pt AS src, r.typeId AS rel_typeId, r.typeTerm AS rel_type, d.pt AS dst\n",
    "LIMIT 25\n",
    "\"\"\", {\"seed\": seed})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d16cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8956237-93c9-4918-b812-31e778ed56d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
